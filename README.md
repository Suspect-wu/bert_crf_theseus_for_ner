# bert_crf_theseus_for_ner

`theseus_bert_crf` ：采用模型压缩算法`BERT-of-Theseus`[《BERT-of-Theseus: Compressing BERT by Progressive Module Replacing》](https://arxiv.org/abs/2002.02925)

`data` : 存放人民日报数据集

`rpberta_zh_l12` ：存放预训练模型

